## 零、服务网格与 API 网关

Istio 服务网格自带的 API 网关功能比较有局限性，实际应用中还是需要结合第三方 API 网关，或者在 Envoy
上深度开发，才能满足需求。

关于 Istio 与 APISIX/Kong 等其他网关的集成，详见
[Ingress / API Gateway 与服务网格集成 {#api-gateway-plus-service-mesh](../../ingress-egress/README.md#api-gateway-plus-service-mesh)

## 一、控制数据面 proxy 的启动、终止顺序

### 预先启动 proxy，或者说在 proxy 启动后再启动其他容器

Istio 1.7 新增了一个功能:
[delay the application start until after the sidecar is started](https://istio.io/latest/news/releases/1.7.x/announcing-1.7/change-notes/#traffic-management)

通过设置 operator 参数 `values.global.proxy.holdApplicationUntilProxyStarts=true`，就能全局启用此功
能，让主容器在 Sidecar 就绪后启动，避免主容器因为网络未就绪而 Crash.

或者在 pod 上添加如下注解也是一样的效果（只在该 pod 上生效）：

```yaml
annotations:
  # https://istio.io/latest/docs/reference/config/istio.mesh.v1alpha1/#ProxyConfig
  proxy.istio.io/config: |
    holdApplicationUntilProxyStarts: true
```

建议：通常只有一启动就需要访问外部网络的服务，会有这个问题，因此我认为应该按需在每个 Pod 上启用此功
能，没必要改全局配置。

### 为主容器及 Sidecar 均添加 preStop 参数

> https://github.com/hashicorp/consul-k8s/issues/650

首先，我在 [K8s 最佳实践](./../../最佳实践.md) 的「优雅停止（Gracful Shutdown）与 502/504 报错」详细
说明过，为什么要为 Pod 添加 `preStop`.

在 Sidecar 代理了 Pod 流量的情况下，上述问题会变得更复杂一点——还需要考虑一个关闭顺序的问题：

- 如果在 Envoy 已关闭，有新的请求再进来，将会导致 504
  - 所以 Envoy 最好在 Terminating 至少 3s 后才能关，确保 Istio 网格配置已完全更新
- 如果在 Envoy 还没停止时，主容器先关闭，然后又有新的请求再进来，Envoy 将因为无法连接到 upstream 导
  致 503
  - 所以主容器也最好在 Terminating 至少 3s 后，才能关闭。
- 如果主容器处理还未处理完遗留请求时，Envoy 或者主容器的其中一个停止了，会因为 tcp 连接直接断开连接
  导致 502
  - 因此 Envoy 必须在主容器处理完遗留请求后（即没有 tcp 连接时），才能关闭

所以总结下：Envoy 及主容器的 `preStop` 都至少得设成 3s，并且在「没有 tcp 连接」时，才能关闭，避免出
现 502/503/504.

主容器的修改方法在前文中已经写过了，下面介绍下 Envoy 的修改方法。

和主容器一样，Envoy 也能直接加 `preStop`，修改 `istio-sidecar-injector` 这个 `configmap`，在 sidecar
里添加 preStop sleep 命令:

```yaml
containers:
  - name: istio-proxy
    # 添加下面这部分
    lifecycle:
      preStop:
        exec:
          command:
            - /bin/sh
            - -c
            - "while [ $(netstat -plunt | grep tcp | grep -v envoy | wc -l | xargs) -ne 0 ]; do sleep
              1; done"
```

#### terminationDrainDuration

> https://istio.io/latest/docs/reference/config/istio.mesh.v1alpha1/#ProxyConfig-termination_drain_duration

根据官方文档所言，Istio 在收到 SIGTERM 信号后，默认只等待 5s，然后就 kill 掉所有还存活的 envoy processes，强制退出。
可通过 `terminationDrainDuration` 这一参数调整这个等待时长。

```yaml
annotations:
  # https://istio.io/latest/docs/reference/config/istio.mesh.v1alpha1/#ProxyConfig
  proxy.istio.io/config: |
    terminationDrainDuration: 30s
```

但是单纯改这个参数可能效果不佳，主要有几点：

- istio sidecar 跟 Pod 中的其他容器会同时收到 SIGTERM 信号，如果其他容器未妥善处理这一信号，只有 istio sidecar 会等待连接安全关闭，那是没用的。
- 因为 K8s 的很多动作都是异步进行的，可能会存在一些边缘情况，譬如 Pod 在被从 EndpointSlices 移除之前有请求被分配了过来，而 Envoy 已经收到了 SIGTERM 信号并拒绝新请求，导致个别请求返回 503 等报错。

在流量比较高的情况下，上述的异步边缘情况是很可能发生的，因此最稳妥的方式仍然是使用 preStop.
如果请求量比较小倒是可以忽略。

如果希望通过信号处理的方式来解决这个问题，需要统一调整：

1. 外层 LoadBalancer 的请求 timeout 时长要调整到期望值（如 30s）
2. Istio 要将 Sidecar 的 `terminationDrainDuration` 设置为期望的超时时间
3. 业务容器要设置 SIGTERM 信号处理器，等待请求处理完毕才关闭
4. Pod 的 `terminationGracePeriodSeconds` 也要设置为比期望的超时时间更长

## [转发客户端 IP/证书](https://istio.io/latest/docs/ops/configuration/traffic-management/network-topologies/)

全局配置：

```yaml
apiVersion: install.istio.io/v1alpha1
kind: IstioOperator
spec:
  meshConfig:
    defaultConfig:
      gatewayTopology:
        numTrustedProxies: 2
        forwardClientCertDetails: APPEND_FORWARD # 通常只在使用 mTLS 双向认证时，服务端才会要求转发证书
```

pod 级别的配置：

```yaml
---
metadata:
  annotations:
    "proxy.istio.io/config":
      '{"gatewayTopology" : { "numTrustedProxies": 2, "forwardClientCertDetails": APPEND_FORWARD } }'
```

## 二、Pod 预热功能 - slow start

目前 Istio 仍然欠缺类似
[AWS ALB](https://aws.amazon.com/about-aws/whats-new/2018/05/application-load-balancer-announces-slow-start-support/)/[nginx](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#slow_start)
的 `slow_start` 的能力，缓慢地将流量切给新建的 Pods，相关进展如下：

- Istio 1.11 目前还没有进
  展：[Ability to gradually warm services - Istio issues](https://github.com/istio/istio/issues/21228)
- Envoy 1.20+ 已支持 slow_start 模
  式：[Slow start mode - envoy](https://www.envoyproxy.io/docs/envoy/v1.20.0/intro/arch_overview/upstream/load_balancing/slow_start#arch-overview-load-balancing-slow-start)

应该可以通过 EnvoyFilter 提前用上这个能力，待研究

## 三、HPA 扩缩容

Pod 在添加 Sidecar 后，HPA 扩缩容的指标会受到影响。

参见
[Horizontal Pod Autoscaler - Pod 自动扩缩容](../../autoscaling/Horizontal%20Pod%20Autoscaler.md)

## 四、在特定 Pods 上启用 access log:

方法一：使用新的 Telemetry API

- https://github.com/istio/istio.io/issues/7613#issuecomment-1009693940

方法二：使用 EnvoyFilter:
[./envoyfilters/enable-accesslog.yaml](./envoyfilters/enable-accesslog.yaml)

## 五、直接返回响应 - Direct Response

> https://github.com/istio/istio/issues/29264

Istio 只支持 redirect，缺乏除 Redirect 之外直接返回响应的能力，所有的语义目前都只支持转发到某个上游
Workload，直接返回响应需要借助 EnvoyFilter 或其他手段实现。

方法一，是使用 EnvoyFilter，如下是一个直接在 IngressGateway 上面返回 200 的例
子：[./envoyfilters/direct_response.yaml](./envoyfilters/direct_response.yaml)

方法二呢，是专门在集群跑一个程序专门用来处理这类请求，比如直接定义几个处理方法:

- Path 为 `/direct_response/xxx` 或者 `Header` 包含 `direct_response: xxx`，直接返回状态码 xxx

这样就可以直接在 VirtualService 上通过 rewrite uri 或者设置 headers，然后转发到这个「Direct
Response」服务来达到返回固定请求的目的。

## 六、Istio 去除响应 Headers

在结合使用 Nginx/APISIX/Kong 等自定义网关与 Istio 时，给它们注入 Sidecar 后会发现响应头中带了些
`x-envoy-` 开头的信息，这一是浪费流量，二是暴露出这些信息存在风险！

- 相关 issue
  - [Unable to remove server header](https://github.com/istio/istio/issues/13861)
  - [Strip internal mesh-machinery headers when sending requests/responses out of mesh](https://github.com/istio/istio/issues/17635)

总结下上述 Issue 的内容，目前的解决方法 Envoyfilter 配
置：[./envoyfilters/remove-envoy-response-headers.yaml](./envoyfilters/remove-envoy-response-headers.yaml)

## 七、Istio Sidecar 代理了不需要代理的流量导致性能差

Istio Sidecar 默认会代理 Pod 的 inbound 以及 outbound 两部分流量，但是有些场景下其实是不需要拦截的，
比如：

- 如果使用了 APISIX/Kong 作为入口网关，其实它的 Istio Sidecar 不需要拦截 inbound 流量，APISIX 会处理
  好这些
- 如果服务直接访问公网域名，通常都会直接走 443/80 端口，这部分流量通常也不需要 istio 做额外处理

为 pod 添加 annotation，即可告诉 Istio 不要拦截 inbound/outbound 流量：

```yaml
annotations:
  # https://istio.io/latest/docs/reference/config/annotations/
  traffic.sidecar.istio.io/excludeInboundPorts: "8080,9090" # 不拦截进入 pod 8080/9090 端口的流量
  traffic.sidecar.istio.io/excludeOutboundPorts: "80,443" # 不拦截从 pod 出去到其他域名的 80/443 端口的流量
```

## 七、重写 Host 字段的值

仍然假设我们使用了 APISIX/Kong 作为入口网关，那么具体的路由逻辑其实都是已经由它们处理了。

为了在 Istio 上实现统一的流量控制，我们会在 APISIX 上将 Host 直接修改为服务名，这样服务网格就只需要
根据服务名来匹配 host 字段，然后进行流量切分、流量镜像等操作即可。

这里就有个问题——有的服务确实需要获取到客户端传递的 Host 请求头，但是上面我们已经将 Host 直接改写为服
务名了！通用的解决方案是：

1. 在 APISIX 侧修改 Host 为服务名的同时，将 `X-Forwarded-Host` 设置为原始的 `Host` 信息，然后再转发
   给 Istio 服务网格。
2. Istio 服务网格首先根据 Host 的信息匹配 VirtualService，进行相应的操作
3. 然后 Istio 将 `Host` 的内容再还原为 `X-Forwarded-Host` 中的值
4. Istio 再将请求转发到具体的 Workloads.

其中第三步还原 Host 的逻辑，可以通过此 EnvoyFilter 实
现：[./envoyfilters/rewrite-host-header.yaml](./envoyfilters/rewrite-host-header.yaml)
